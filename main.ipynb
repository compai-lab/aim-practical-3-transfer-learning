{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI in Medicine I - Practical 3: Transfer Learning\n",
    "\n",
    "Generating good labels for medical datasets is an expensive and time consuming task, especially on tasks such as segmentation where expert radiologists are often required.\n",
    "Often we are faced with datasets that have scarce labels or none at all and must rely on selfsupervised pretraining methods to increase our performance.\n",
    "We will continue to use the brain MRI dataset from the previous practicals.\n",
    "The Jupyter Notebook provided contains some preliminary code you can use and some function prototypes that you are expected to fill in.\n",
    "The deliverables for the submission an archive containing the code provided completed as well as a short report explaining your strategies and choices for each task in this practical.\n",
    "\n",
    "\n",
    "**Make sure to select the correct runtime when working in Google Colab (GPU)**\n",
    "\n",
    "### Read the text descriptions and code cells carefully and look out for the cells marked with 'TASK' and 'ADD YOUR CODE HERE'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this cell when in Google Colab\n",
    "! git init\n",
    "! git remote add origin https://github.com/compai-lab/aim-practical-3-transfer-learning\n",
    "! git fetch\n",
    "! git checkout -t origin/main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://www.dropbox.com/s/w9njau9t6rrheel/brainage-data.zip\n",
    "! unzip brainage-data.zip\n",
    "! wget https://www.dropbox.com/s/f5mt8p9pkszff3x/brainage-testdata.zip\n",
    "! unzip brainage-testdata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install monai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "\n",
    "from monai.networks.nets import UNet\n",
    "from monai.losses import DiceCELoss\n",
    "from monai.transforms import AsDiscrete\n",
    "from monai.metrics import compute_dice\n",
    "\n",
    "\n",
    "from data_utils import get_image_dataloaders\n",
    "from utils import AvgMeter, seed_everything\n",
    "%load_ext tensorboard\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started and familiarise ourselves with the data\n",
    "\n",
    "We provide the data of 652 subjects from which we use 500 for training, 47 for validation, and the rest for testing your final model.\n",
    "The following cells provide helper functions to load the data and provide an overview and visualization of the statistics over the total population of the 652 subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('./data/brain_age/meta/meta_data_regression_train.csv')\n",
    "val_df = pd.read_csv('./data/brain_age/meta/meta_data_segmentation_train.csv')\n",
    "test_df = pd.read_csv('./data/brain_age/meta/meta_data_regression_test.csv')\n",
    "train_df['subject_id']\n",
    "id_overlap = pd.merge(train_df, val_df, on='subject_id', how='inner')\n",
    "assert len(id_overlap)==0\n",
    "id_overlap = pd.merge(train_df, test_df, on='subject_id', how='inner')\n",
    "assert len(id_overlap)==0\n",
    "id_overlap = pd.merge(val_df, test_df, on='subject_id', how='inner')\n",
    "assert len(id_overlap)==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation\n",
    "\n",
    "We again wish to segment our brains using deep neural network. The following code is a basic example of how to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Dataset Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_segmentation(config, model, optimizer, train_loader, val_loader):\n",
    "    model.train()\n",
    "    step = 0\n",
    "    checks = 0\n",
    "    best_val_loss = float('Inf')\n",
    "    avg_loss = AvgMeter()\n",
    "    avg_dice = AvgMeter()\n",
    "    \n",
    "    criterion = DiceCELoss(include_background=False, softmax=True)\n",
    "    postprocess = AsDiscrete(argmax=True, to_onehot=4)\n",
    "\n",
    "\n",
    "    while True:\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(config.device)\n",
    "            y = y.to(config.device)\n",
    "\n",
    "            # Training step\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x)\n",
    "            loss = criterion(pred, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            pred_binarized = []\n",
    "            y_binarized = []\n",
    "            for i in range(pred.shape[0]):\n",
    "                pred_binarized.append(postprocess(pred[i]))\n",
    "                y_binarized.append(postprocess(y[i]))\n",
    "            pred_binarized = torch.stack(pred_binarized)\n",
    "            y_binarized = torch.stack(y_binarized)\n",
    "\n",
    "            dice = compute_dice(pred_binarized, y_binarized, include_background=False).mean()\n",
    "\n",
    "            avg_loss.add(loss.detach().item())\n",
    "            avg_dice.add(dice.detach().item())\n",
    "\n",
    "            # Increment step\n",
    "            step += 1\n",
    "\n",
    "            if step % config.log_freq == 0 and not step % config.val_freq == 0:\n",
    "                train_loss = avg_loss.compute()\n",
    "                train_dice = avg_dice.compute()\n",
    "\n",
    "            # Validate and log at validation frequency\n",
    "            if step % config.val_freq == 0:\n",
    "                # Reset avg_loss\n",
    "                train_loss = avg_loss.compute()\n",
    "                train_dice = avg_dice.compute()\n",
    "                avg_loss = AvgMeter()\n",
    "                avg_dice = AvgMeter()\n",
    "\n",
    "                # Get validation results\n",
    "                val_results = validate_segmentation(\n",
    "                    model,\n",
    "                    val_loader,\n",
    "                    config,\n",
    "                    criterion,\n",
    "                    postprocess\n",
    "                )\n",
    "\n",
    "                # Print current performance\n",
    "                print(f\"Finished step {step} of {config.num_steps}. \"\n",
    "                      f\"Train loss: {train_loss} - \"\n",
    "                      f\"Train Dice: {train_dice} - \"\n",
    "                      f\"val loss: {val_results['val/loss']:.4f} - \"\n",
    "                      f\"val Dice: {val_results['val/Dice']:.4f} - \"\n",
    "                      f\"val Dice_CSF: {val_results['val/Dice_CSF']:.4f} - \"\n",
    "                      f\"val Dice_WM: {val_results['val/Dice_WM']:.4f} - \"\n",
    "                      f\"val Dice_GM: {val_results['val/Dice_GM']:.4f} - \")\n",
    "\n",
    "                # Check if the validation loss has stopped increasing\n",
    "                ### ADD YOUR CODE HERE ###\n",
    "\n",
    "                ### END ###\n",
    "            \n",
    "            if step >= config.num_steps:\n",
    "                print(f'\\nFinished training after {step} steps\\n')\n",
    "                return model, step\n",
    "\n",
    "\n",
    "def validate_segmentation(model, val_loader, config, criterion, postprocess):\n",
    "    model.eval()\n",
    "    avg_val_loss = AvgMeter()\n",
    "    avg_val_dice = AvgMeter()\n",
    "    avg_val_dice_1 = AvgMeter()\n",
    "    avg_val_dice_2 = AvgMeter()\n",
    "    avg_val_dice_3 = AvgMeter()\n",
    "    for x, y in val_loader:\n",
    "        x = x.to(config.device)\n",
    "        y = y.to(config.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(x)    \n",
    "        loss = criterion(pred, y)\n",
    "        \n",
    "        pred_binarized = []\n",
    "        y_binarized = []\n",
    "        for i in range(pred.shape[0]):\n",
    "            pred_binarized.append(postprocess(pred[i]))\n",
    "            y_binarized.append(postprocess(y[i]))\n",
    "        pred_binarized = torch.stack(pred_binarized)\n",
    "        y_binarized = torch.stack(y_binarized)\n",
    "\n",
    "        dice = compute_dice(pred_binarized, y_binarized, include_background=False)\n",
    "        mean_dice = dice.mean()\n",
    "        mean_dice_per_class = dice.mean(dim=0)\n",
    "        avg_val_loss.add(loss.item())\n",
    "        avg_val_dice.add(mean_dice.item())\n",
    "        avg_val_dice_1.add(mean_dice_per_class[0].item())\n",
    "        avg_val_dice_2.add(mean_dice_per_class[1].item())\n",
    "        avg_val_dice_3.add(mean_dice_per_class[2].item())\n",
    "\n",
    "        \n",
    "    model.train()\n",
    "    return {\n",
    "        'val/loss': avg_val_loss.compute(),\n",
    "        'val/Dice': avg_val_dice.compute(),\n",
    "        'val/Dice_CSF': avg_val_dice_1.compute(),\n",
    "        'val/Dice_WM': avg_val_dice_2.compute(),\n",
    "        'val/Dice_GM': avg_val_dice_3.compute()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets set some basic hyperparameters\n",
    "config = Namespace()\n",
    "config.img_size = 96\n",
    "config.batch_size = 16\n",
    "config.num_workers = 0\n",
    "\n",
    "config.log_dir = './logs'\n",
    "config.val_freq = 50\n",
    "config.log_freq = 10\n",
    "\n",
    "config.seed = 0\n",
    "config.device = 'cuda'\n",
    "config.autoencoder = False\n",
    "\n",
    "config.lr = 1e-3\n",
    "config.betas = (0.9, 0.999)\n",
    "\n",
    "config.num_steps = 1500\n",
    "config.patience = 5\n",
    "\n",
    "seed_everything(config.seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_train_df = pd.read_csv('./data/brain_age/meta/meta_data_regression_train.csv')\n",
    "low_data_train_df = all_train_df.sample(n=200, random_state=12)\n",
    "low_data_train_df.to_csv('./data/brain_age/meta/meta_data_regression_train_lowdata_200.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "dataloaders_fulldata_segmentations = get_image_dataloaders(\n",
    "    img_size=config.img_size,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=config.num_workers,\n",
    "    segmentations = True,\n",
    "    low_data = '200'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TASK: MONAI UNET\n",
    "For todays exercise we will be using a library called MONAI which has some very useful tools for medical imaging. Our task is segmentation and so we will be using a classic UNet. Think about how many channels, strides and residual unets you want to include. Remember that for smaller datasets, less parameters is often an advantage. Play around with different settings and see how the performance changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model\n",
    "model_unet = UNet(\n",
    "  spatial_dims=3,\n",
    "  out_channels=4,\n",
    "  ### ADD YOUR CODE HERE ###\n",
    "\n",
    "  ### END ###\n",
    ").to(config.device)\n",
    "\n",
    "\n",
    "# Init optimizers\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model_unet.parameters(),\n",
    "    lr=config.lr,\n",
    "    betas=config.betas\n",
    ")\n",
    "\n",
    "model_unet, step = train_segmentation(\n",
    "    config=config,\n",
    "    model=model_unet,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=dataloaders_fulldata_segmentations['train'],\n",
    "    val_loader=dataloaders_fulldata_segmentations['val']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test_results = validate_segmentation(model_unet, dataloaders_fulldata_segmentations['test'], config, DiceCELoss(include_background=False, softmax=True), AsDiscrete(argmax=True, to_onehot=4))\n",
    "print(f'Test loss: {test_results[\"val/loss\"]:.4f}')\n",
    "print(f'Test Mean Dice: {test_results[\"val/Dice\"]:.4f}')\n",
    "print(f'Test Dice_CSF: {test_results[\"val/Dice_CSF\"]:.4f}')\n",
    "print(f'Test Dice_WM: {test_results[\"val/Dice_WM\"]:.4f}')\n",
    "print(f'Test Dice_GM: {test_results[\"val/Dice_GM\"]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK: Low Label Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we don't have labels for all of our samples, or have multiple datasets, where we might have labels for one dataset but not the other. \n",
    "Especially in medicine, where expert labels can be expensive to generate, we have to combine datasets to have enough data for training. \n",
    "\n",
    "Here we will simulate the scenario that our radiologists don't like us and have decided to only segment three brains.\n",
    "\n",
    "Retrain the model and see what happens to our test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "all_train_df = pd.read_csv('./data/brain_age/meta/meta_data_regression_train.csv')\n",
    "low_data_train_df = all_train_df.sample(n=3, random_state=12)\n",
    "low_data_train_df.to_csv('./data/brain_age/meta/meta_data_regression_train_lowdata_3.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders_lowdata_segmentations = get_image_dataloaders(\n",
    "    img_size=config.img_size,\n",
    "    batch_size=config.batch_size,\n",
    "    num_workers=config.num_workers,\n",
    "    low_data= '3',\n",
    "    segmentations = True,\n",
    "    train_only = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_unet_lowdata = UNet(\n",
    "  spatial_dims=3,\n",
    "  out_channels=4,\n",
    "### ADD YOUR CODE HERE ###\n",
    "\n",
    "### END ###\n",
    ").to(config.device)\n",
    "\n",
    "\n",
    "# Init optimizers\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model_unet_lowdata.parameters(),\n",
    "    lr=config.lr,\n",
    "    betas=config.betas\n",
    ")\n",
    "\n",
    "config.patience = 5\n",
    "config.num_steps = 3000\n",
    "model_unet_lowdata, step = train_segmentation(\n",
    "    config=config,\n",
    "    model=model_unet_lowdata,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=dataloaders_lowdata_segmentations['train'],\n",
    "    val_loader=dataloaders_fulldata_segmentations['val']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test_results = validate_segmentation(model_unet_lowdata, dataloaders_fulldata_segmentations['test'], config, DiceCELoss(include_background=False, softmax=True), AsDiscrete(argmax=True, to_onehot=4))\n",
    "print(f'Test loss: {test_results[\"val/loss\"]:.4f}')\n",
    "print(f'Test Mean Dice: {test_results[\"val/Dice\"]:.4f}')\n",
    "print(f'Test Dice_CSF: {test_results[\"val/Dice_CSF\"]:.4f}')\n",
    "print(f'Test Dice_WM: {test_results[\"val/Dice_WM\"]:.4f}')\n",
    "print(f'Test Dice_GM: {test_results[\"val/Dice_GM\"]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK: What happens to our training dynamics and duration now that we have less data? \n",
    "\n",
    "Maybe setting a fixed amount of steps is not the best idea...\n",
    "Implement some form of early stopping in the training loop that stops training after the validation loss does not improve after N checks.\n",
    "Play around with this patience parameter. How does it affect test accuracy? Why?\n",
    "\n",
    "Retrain the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TASK: Autoencoder\n",
    "\n",
    "We can't seem to achieve our previous performance because we don't have enough labeled samples. We still have the rest of the data, we just don't have any labels. Maybe we can improve our performance by doing some initial unsupervised learning over the full, unlabeled dataset before finetuning on our three labeled samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(config, model, optimizer, train_loader, val_loader):\n",
    "    model.train()\n",
    "    step = 0\n",
    "    avg_loss = AvgMeter()\n",
    "\n",
    "    while True:\n",
    "        for x, y in train_loader:\n",
    "            x = x.to(config.device)\n",
    "            y = y.to(config.device)\n",
    "            \n",
    "\n",
    "            # Training step\n",
    "            optimizer.zero_grad()\n",
    "            pred = model(x)\n",
    "            loss = torch.pow((pred - x), 2).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_loss.add(loss.detach().item())\n",
    "\n",
    "            # Increment step\n",
    "            step += 1\n",
    "\n",
    "            # Validate and log at validation frequency\n",
    "            if step % config.val_freq == 0:\n",
    "                # Reset avg_loss\n",
    "                train_loss = avg_loss.compute()\n",
    "                avg_loss = AvgMeter()\n",
    "\n",
    "                # Get validation results\n",
    "                val_results = validate_autoencoder(\n",
    "                    model,\n",
    "                    val_loader,\n",
    "                    config\n",
    "                )\n",
    "\n",
    "                # Print current performance\n",
    "                print(f\"Finished step {step} of {config.num_steps}. \"\n",
    "                      f\"Train loss: {train_loss} - \"\n",
    "                      f\"val loss: {val_results['val/loss']:.4f} - \"\n",
    "                      f\"val MAE: {val_results['val/MAE']:.4f}\")\n",
    "\n",
    "            if step >= config.num_steps:\n",
    "                print(f'\\nFinished training after {step} steps\\n')\n",
    "                return model, step\n",
    "\n",
    "\n",
    "def validate_autoencoder(model, val_loader, config, show_plot=False):\n",
    "    model.eval()\n",
    "    avg_val_loss = AvgMeter()\n",
    "    preds = []\n",
    "    targets = []\n",
    "    for x, y in val_loader:\n",
    "        x = x.to(config.device)\n",
    "        y = y.to(config.device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred = model(x)\n",
    "        loss = torch.pow((pred - x), 2).mean()\n",
    "        avg_val_loss.add(loss.item())\n",
    "        preds.append(pred.cpu())\n",
    "        targets.append(x.cpu())\n",
    "\n",
    "    preds = torch.cat(preds)\n",
    "    targets = torch.cat(targets)\n",
    "    mae = mean_absolute_error_image(preds, targets)\n",
    "        \n",
    "    model.train()\n",
    "    return {\n",
    "        'val/loss': avg_val_loss.compute(),\n",
    "        'val/MAE': mae,\n",
    "    }\n",
    "\n",
    "\n",
    "def mean_absolute_error_image(preds: Tensor, targets: Tensor) -> float:\n",
    "    \"\"\"Compute the mean absolute error between predictions and targets\"\"\"\n",
    "    return (preds - targets).abs().mean().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model\n",
    "# HINT: If you aren´t getting the performance you expect, try to change the number of channels and the number of res units\n",
    "model_ae = UNet(\n",
    "  ### ADD YOUR CODE HERE ###\n",
    "\n",
    "  ### END ###\n",
    ").to(config.device)\n",
    "\n",
    "# Init optimizers\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model_ae.parameters(),\n",
    "    lr=config.lr,\n",
    "    betas=config.betas\n",
    ")\n",
    "\n",
    "config.num_steps = 1500\n",
    "model_ae, step = train_autoencoder(\n",
    "    config=config,\n",
    "    model=model_ae,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=dataloaders_fulldata_segmentations['train'],\n",
    "    val_loader=dataloaders_fulldata_segmentations['val']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TASK: Visualize Results\n",
    "\n",
    "Plot both the original brains and the reconstructed brains above one another to see how good the autoencoder performed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_images = next(iter(dataloaders_fulldata_segmentations['val']))[0].to(config.device)\n",
    "\n",
    "f, axarr = plt.subplots(2, 3)\n",
    "orig_image = orig_images[0, 0].cpu().numpy()\n",
    "H, W, D = orig_image.shape\n",
    "axarr[0][0].imshow(orig_image[H // 2, :, :], cmap='gray')\n",
    "axarr[0][1].imshow(orig_image[:, W // 2, :], cmap='gray')\n",
    "axarr[0][2].imshow(orig_image[:, :, D // 2], cmap='gray')\n",
    "### ADD YOUR CODE HERE ###\n",
    "\n",
    "### END ###\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks pretty good! \n",
    "\n",
    "#### TASK: Transfer Learning\n",
    "Now lets see if its learned any useful features that can help us in our segmentation task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init model\n",
    "model_ae_segmenter = UNet(\n",
    "  ### ADD YOUR CODE HERE ###\n",
    "  \n",
    "  ### END ###\n",
    ").to(config.device)\n",
    "\n",
    "# Init optimizers\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model_ae_segmenter.parameters(),\n",
    "    lr=config.lr,\n",
    "    betas=config.betas\n",
    ")\n",
    "\n",
    "# Load the weights from the autoencoder using the state_dict\n",
    "# HINT: Remove the weights from the decoder as we have a different number of channels now and a different task. \n",
    "# HINT: Take a look at the arguments if you get errors that might be ok to ignore\n",
    "### ADD YOUR CODE HERE ###\n",
    "\n",
    "### END ###\n",
    "\n",
    "# Sometimes after pretraining in very low data regimes it can help to freeze the encoder, to preserve the features learned over the large dataset.\n",
    "# Write some code to freeze only the encoder here\n",
    "### ADD YOUR CODE HERE ###\n",
    "\n",
    "### END ###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "model_ae_segmenter, step = train_segmentation(\n",
    "    config=config,\n",
    "    model=model_ae_segmenter,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=dataloaders_lowdata_segmentations['train'],\n",
    "    val_loader=dataloaders_fulldata_segmentations['val']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "test_results = validate_segmentation(model_ae_segmenter, dataloaders_fulldata_segmentations['test'], config, DiceCELoss(include_background=False, softmax=True), AsDiscrete(argmax=True, to_onehot=4))\n",
    "print(f'Test loss: {test_results[\"val/loss\"]:.4f}')\n",
    "print(f'Test Dice: {test_results[\"val/Dice\"]:.4f}')\n",
    "print(f'Test Dice_CSF: {test_results[\"val/Dice_CSF\"]:.4f}')\n",
    "print(f'Test Dice_WM: {test_results[\"val/Dice_WM\"]:.4f}')\n",
    "print(f'Test Dice_GM: {test_results[\"val/Dice_GM\"]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! It looks like we were able to boost our mean Dice score by 2-3 points.\n",
    "\n",
    "#### TASK: Frozen vs Unfrozen Weights\n",
    "Retrain the model above, this time with fully trainable weights. How does our performance change? Why do you think this is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TASK: Autoencoder Performance VS Downstream Task\n",
    " \n",
    "We can definitely improve our autoencoder reconstruction performance by training for longer. Maybe this isn't ideal for our segmentation task, but we can try it out. Try training for different number of steps and see how the reconstruction performance changes. What is the best number of steps?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MedicalNet: Using Pretrained Weights from the Internet\n",
    "\n",
    "Often times it helps to use weights trained by other people on larger datasets. In 3D Medical Imaging for example, MedicalNet (https://github.com/Tencent/MedicalNet) is a collection of 3D ResNets that have been trained on 23 segmentation datasets. Although there are other organs included, see how well the learned weights transfer to our task. Download and and use MedicalNet for our segmentation task. Is this better than selfsupervised training over dataset?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('selfsuper')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a21be7fe9607dfe0c8ee311f8a5f36f314167f49973cd8e355a42459a56bba0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
